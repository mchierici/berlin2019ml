{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJfNUgelLKKI"
   },
   "source": [
    "# <center>Machine learning from scratch - Day II</center>\n",
    "## <center>18 July, 2019 @ Bayer AG R&D, Berlin, Germany</center>\n",
    "### <center>Marco Chierici & Margherita Francescatto</center>\n",
    "#### <center>_FBK/MPBA_</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1GLtJ7YLKKJ"
   },
   "source": [
    "Recap. We are using a subset of the SEQC neuroblastoma data set [Zhang et al, Genome Biology, 2015] consisting of 272 samples (136 training, 136 test). The data was preprocessed a bit to facilitate the progress of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Dhu_6_ULKKK"
   },
   "source": [
    "We start by loading the modules we need to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jT_SUG13LKKL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt ## for plotting\n",
    "import pandas as pd ## for reading text files and manipulating data frames\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors ## kNN classifier\n",
    "%matplotlib inline\n",
    "np.random.seed(42) ## set random seed just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qOlPPJmmLKKO"
   },
   "source": [
    "Define files to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  for convenience, define the data directory as a variable\n",
    "DATA_DIR = \"data/\"\n",
    "DATA = DATA_DIR + \"MAV-G_272.txt\"\n",
    "LABS = DATA_DIR + \"labels.txt\"\n",
    "data = pd.read_csv(DATA, sep = \"\\t\")\n",
    "\n",
    "# We drop the first column from the train and test expression sets, since it's just the sample IDs...\n",
    "data = data.drop('sampleID', axis=1)\n",
    "# ...and store the data into Numpy arrays.\n",
    "X = data.values\n",
    "# Now we read in the files containing labels and select the column with the CLASS target\n",
    "labs = pd.read_csv(LABS, sep = \"\\t\")\n",
    "class_lab = labs[['CLASS']]\n",
    "y = class_lab.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 52229)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# following our consolidated practice, print the shape of the data as a sanity check:\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13LEke6Js720"
   },
   "source": [
    "# 2. Data partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IIhs_0Exo1B"
   },
   "source": [
    "### Hold-out strategy\n",
    "\n",
    "The idea behind data partitioning is to split your original data set into a **train** portion (for developing your machine learning model) and a **test** portion (for evaluating the performance of the trained model).\n",
    "\n",
    "The simplest and most straightforward way to partition your data set is to randomly split it in two groups (*hold-out strategy*).\n",
    "\n",
    "You achieve this using scikit-learn's function `train_test_split`, in the `model_selection` submodule.\n",
    "\n",
    "For example, let's split the data (X) into 80% train and 20% test (note the argument `test_size=0.2`). Use a random_state of your choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqbLHGVP2cAH"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOKwQzhK8tVY"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "What is the random_state?\n",
    "\n",
    "Whenever randomness is involved in a computer program, we need to rely on some sort of workaround because computers follow their instructions blindly and they are therefore completely predictable.\n",
    "\n",
    "One approach relies on *Pseudo-Random Number Generators* (PRNGs). \n",
    "\n",
    "PNRGs are algorithms that use mathematical formulas or precalculated tables to produce sequences of numbers that appear random. \n",
    "\n",
    "PNRGs are initialized by a *seed* (an integer), so that *the same seed yields the same sequence of pseudo-random numbers*. This is useful for reproduciblity.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "## first you need to create a \"scaler\" object\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "## then you actually scale data by fitting the scaler object on the data\n",
    "scaler.fit(x_tr)\n",
    "x_tr = scaler.transform(x_tr)\n",
    "x_ts = scaler.transform(x_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FErPMN8F6sb9"
   },
   "source": [
    "# 4. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides you access to several models via a very convenient _fit_ and _predict_ interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7xRxdjO6vTY"
   },
   "source": [
    "## 4.1 k-NN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnHfIehl62Js"
   },
   "source": [
    "For example, let's fit a k-NN model on the whole training data and then use it to predict the labels of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6P24VUwQk3XG"
   },
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cg8TpDATk3XI",
    "outputId": "e9658389-474c-4bf5-f196-11d4518311b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5pHIVW2k3XM"
   },
   "outputs": [],
   "source": [
    "y_pred_knn = knn.predict(x_ts) # predict labels on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Crr_2DwX7f1Z"
   },
   "source": [
    "_In general, a classifier has **parameters** that need to be tuned. Default choices are not good in all situations._\n",
    "\n",
    "_For example, in k-NN the main parameter is the **number of neighbors** used in the nearest neighbors algorithm._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBsDZNnXk3XP"
   },
   "source": [
    "To evaluate the predictions we need some kind of metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L88ilJJG-Cnf"
   },
   "source": [
    "## Performance assessment: Confusion matrix\n",
    "\n",
    "In this example, the first row is class 0, so the confusion matrix will look like:\n",
    "\n",
    "|      |  |  Predicted  |    |\n",
    "|------|-----------|----|----|\n",
    "|      |           | 0 | 1  |\n",
    "| True | 0        | TN | FP |\n",
    "|      | 1         | FN | TP |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JISD2EVQ9Q9Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  7],\n",
       "       [ 0, 33]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = metrics.confusion_matrix(y_ts, y_pred_knn)\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kh9MqHB5cC43"
   },
   "source": [
    "The total number of class 0 test samples (AN = All Negatives) should be equal to the sum of the first row of the confusion matrix, i.e., TN + FP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZVN8GKKdOhy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_ts == 0) # total number of \"class 0\" samples in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoBqoaTGcDVy"
   },
   "source": [
    "Similarly for class 1, i.e., AP = All Positives = TP + FN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PVj7JbxdVk0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_ts==1) # total number of \"class 1\" samples in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kva3wkz5ddap"
   },
   "source": [
    "**Exercise**\n",
    "\n",
    "* Compute the Accuracy, remembering/using the formula ACC = (TN + TP) / (TN + TP + FN + FP)\n",
    "* Compute the Sensitivity (also known as \"Recall\"), using the formula SENS = TP / (TP + FN)\n",
    "\n",
    "Computing metrics by hand is good, but what about a quicker option?\n",
    "\n",
    "As seen in the lectures, Scikit Learn offers a handy broad range of functions to evaluate your classifier through its submodule `metrics`.\n",
    "\n",
    "* Compute the accuracy and sensitivity using the scikit-learn built-in functions `metrics.accuracy_score` and `metrics.recall_score`, taking as input the predicted labels and the true labels\n",
    "* Do you know of another metric that better summarizes the confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC =  0.8727272727272727\n",
      "SENS =  1.0\n"
     ]
    }
   ],
   "source": [
    "tn = conf[0, 0]\n",
    "fp = conf[0, 1]\n",
    "fn = conf[1, 0]\n",
    "tp = conf[1, 1]\n",
    "\n",
    "acc = (tn + tp) / (tn + tp + fn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print(\"ACC = \", acc)\n",
    "print(\"SENS = \", sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC =  0.8727272727272727\n",
      "SENS =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"ACC = \", metrics.accuracy_score(y_ts, y_pred_knn))\n",
    "print(\"SENS = \", metrics.recall_score(y_ts, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqAX0k6UoeZh"
   },
   "source": [
    "Let's consider now the Matthews Correlation Coefficient (MCC):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dl82PZ0Zn5lN"
   },
   "source": [
    "![MCC formula](https://www.researchgate.net/profile/Pablo_Moscato/publication/223966631/figure/fig1/AS:305103086080001@1449753652505/Calculation-of-Matthews-Correlation-Coefficient-MCC-A-Contingency-matrix_W640.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4v0aWAAJrex-"
   },
   "source": [
    "*Q: Do you remember the main features of MCC?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FDN2f1ZAoty0"
   },
   "source": [
    "In scikit-learn it is computed by the `metrics.matthews_corrcoef` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ynxyEsfFk3XV"
   },
   "source": [
    "If we get the MCC for our kNN predictions, we can observe that it is in line with our *a priori* knowledge of the dataset (from the article):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuoRfictk3XW",
    "outputId": "9119acba-9d18-4076-eb3c-8346ba420579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(metrics.matthews_corrcoef(y_ts, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arErpTdvLKKh"
   },
   "source": [
    "So far we focused on the k-NN classifiers. In the previous lecture, however, we explored theoretical aspects related to two other broadly used classifiers: Support Vector Machines (SVMs) and Random Forests (RFs). In this part of tutorial, the first thing we want to do is assessing how these two alternative classification methods perform on our neuroblastoma dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMP7DMy3LKKh"
   },
   "source": [
    "We start with SVM. We first rescale the data, import the relevant model and create an instance of the SVM classifier. Use the same seed used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder: x_tr, x_ts were previously rescaled using the MinMaxScaler.\n",
    "# Now we want to standardize the features, so we need to recreate the original arrays:\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=78)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "## then you actually scale data by fitting the scaler object on the data\n",
    "scaler.fit(x_tr)\n",
    "x_tr = scaler.transform(x_tr)\n",
    "x_ts = scaler.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oY93_AikLKKj"
   },
   "outputs": [],
   "source": [
    "## import support vector classifier (SVC) and create an instance\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pseq_nh7LKKl"
   },
   "source": [
    "Note that the specification _kernel = 'linear'_ implies that a linear kernel will be used. If you remember from the lecture, this means that a linear function is used to define the decision boundaries of the classifier. Alternatives include _‘poly’_ and _‘rbf’_ for polynomial or gaussian kernels respectively. Scikit-learn offers an alternative implementation of linear SVMs. You can find more details in Scikit User Guide. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** always start experimenting with the linear kernel, which is the simplest one; try more complex kernels later on (Occam's razor...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waXcgaLpLKKm"
   },
   "source": [
    "As previously done with the k-NN classifier, we fit an SVM model on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qqc3TmFBLKKn",
    "outputId": "d9ef6c64-9f18-4bea-9167-decaa0ca1820"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple as that. Now we have a fitted SVM model that we can use to make predictions on new data.\n",
    "\n",
    "Of course there are a few parameters that may require tuning: more on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qqc3TmFBLKKn",
    "outputId": "d9ef6c64-9f18-4bea-9167-decaa0ca1820"
   },
   "outputs": [],
   "source": [
    "y_pred_svm = svc.predict(x_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a set of predictions for each entry in the test set. Since we also have the actual labels for each record in the test set, we can use them to assess the performance of the SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lI7vGjulLKKr"
   },
   "source": [
    "Now we give a look at the classification metrics introduced in the first part of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ku0JSF_ALKKs",
    "outputId": "94585c0e-534a-445d-d0ba-92a9bf3a9388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC =  0.9279607271383369\n",
      "ACC =  0.9636363636363636\n",
      "SENS =  0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "print('MCC = ', metrics.matthews_corrcoef(y_ts, y_pred_svm))\n",
    "print('ACC = ', metrics.accuracy_score(y_ts, y_pred_svm))\n",
    "print('SENS = ', metrics.recall_score(y_ts, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to scikit-learn simple API, we can easily create a RandomForest instance and fit it to our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "clf = RFC(n_estimators=500, random_state=42)\n",
    "clf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = clf.predict(x_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a few metrics using the actual test set labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZT6XjB20LKK0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC =  0.894427190999916\n",
      "ACC =  0.9454545454545454\n",
      "SENS =  0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "print('MCC = ', metrics.matthews_corrcoef(y_ts, y_pred_rfc))\n",
    "print('ACC = ', metrics.accuracy_score(y_ts, y_pred_rfc))\n",
    "print('SENS = ', metrics.recall_score(y_ts, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you do? Note that (not surprisingly) there is an element of randomness in a \"random forest\". \n",
    "\n",
    "I'm getting an accuracy of about 94-98%, but \"your mileage may vary\": the precise number will be different each time you run the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the algorithm, some of the supervised models in scikit-learn can also provide the **probability** that a record belongs in each category. \n",
    "\n",
    "For random forest, we can obtain these probabilities by calling the `predict_proba` method on the fitted model. Because we have two categories, 0 (negative) and 1 (positive), scikit-learn will return two category probabilities (the sum across all categories will add up to 1).\n",
    "\n",
    "Looking at the prediction probabilities may be useful to understand on which samples the classifier is \"unsure\" (i.e., the probabilities are around 0.5 for both classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_rfc = clf.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.044 0.956]\n",
      " [0.778 0.222]\n",
      " [0.504 0.496]\n",
      " [0.602 0.398]\n",
      " [0.054 0.946]\n",
      " [0.042 0.958]\n",
      " [0.064 0.936]\n",
      " [0.206 0.794]\n",
      " [0.044 0.956]\n",
      " [0.684 0.316]\n",
      " [0.954 0.046]\n",
      " [0.034 0.966]\n",
      " [0.836 0.164]\n",
      " [0.062 0.938]\n",
      " [0.656 0.344]\n",
      " [0.17  0.83 ]\n",
      " [0.152 0.848]\n",
      " [0.948 0.052]\n",
      " [0.618 0.382]\n",
      " [0.512 0.488]\n",
      " [0.95  0.05 ]\n",
      " [0.896 0.104]\n",
      " [0.868 0.132]\n",
      " [0.974 0.026]\n",
      " [0.07  0.93 ]\n",
      " [0.682 0.318]\n",
      " [0.172 0.828]\n",
      " [0.538 0.462]\n",
      " [0.028 0.972]\n",
      " [0.038 0.962]\n",
      " [0.506 0.494]\n",
      " [0.2   0.8  ]\n",
      " [0.042 0.958]\n",
      " [0.072 0.928]\n",
      " [0.624 0.376]\n",
      " [0.94  0.06 ]\n",
      " [0.528 0.472]\n",
      " [0.058 0.942]\n",
      " [0.028 0.972]\n",
      " [0.044 0.956]\n",
      " [0.004 0.996]\n",
      " [0.132 0.868]\n",
      " [0.956 0.044]\n",
      " [0.064 0.936]\n",
      " [0.11  0.89 ]\n",
      " [0.968 0.032]\n",
      " [0.144 0.856]\n",
      " [0.58  0.42 ]\n",
      " [0.036 0.964]\n",
      " [0.058 0.942]\n",
      " [0.022 0.978]\n",
      " [0.372 0.628]\n",
      " [0.948 0.052]\n",
      " [0.442 0.558]\n",
      " [0.812 0.188]]\n"
     ]
    }
   ],
   "source": [
    "print(prob_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn makes it easy to try different classifiers. \n",
    "\n",
    "Neural networks, naive bayes, random forest, logistic regression, support vector machines, and other algorithms all have a very similar interface (of course the underlying mathematics can be dramatically different!) \n",
    "\n",
    "1. you create an instance of the model (in the variable, say, `clf`), optionally tuning the parameters; \n",
    "2. you fit the model on some training data (`clf.fit(x_tr, y_tr)`); \n",
    "3. you predict the labels of unseen test data (`clf.predict(x_ts)`). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: neural net!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a neural net, you only need to make a few changes to this workbook.\n",
    "\n",
    "First, load the appropriate library\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "Then, call a neural network classifier rather than a random forest model\n",
    "\n",
    "clf = MLPClassifier()\n",
    "\n",
    "Proceed as usual to fit and make predictions.\n",
    "\n",
    "_Et voilà!_ In seconds you are making classification predictions using a neural net model rather than a random forest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a neural net and assess its performance on the test set;\n",
    "* Compare the performance of the classifiers you just used;\n",
    "* Given the performance metrics you assessed, can you say there is a \"best\" classification algorithm? Do you think this algorithm will perform better on a different task / data?\n",
    "\n",
    "Hint: the effectiveness depends on a number of factors, mainly the **classifier parameters** and the **data**. Some data sets just match very well to a particular prediction algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtPbufFSpSxL"
   },
   "source": [
    "**Exercise** \n",
    "\n",
    "* Compare the metrics of the different classifiers. What can you say about this classification task? Do the classifiers learn something?\n",
    "* Which classifier has the best accuracy and MCC?\n",
    "* Are you confident enough that such classifier is able to *generalize* beyond its training set?\n",
    "* Do you know if there is a more robust way to assess the performance of the models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rqkAcvnpxpCx"
   },
   "source": [
    "# 5. Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NqrxSWmp8Zg5"
   },
   "source": [
    "So far we fitted several models on our training data, then we predicted the labels on the test data, computing a set of metrics.\n",
    "\n",
    "How can we know if our model is going to generalize well on new unseen data?\n",
    "\n",
    "We need a more robust way to _estimate_ the model performance and its generalization capabilities.\n",
    "\n",
    "We already used the **hold-out strategy**, with scikit's `train_test_split` function, to split our `X` data into one training/test partition.\n",
    "\n",
    "Partitioning the dataset once is not enough. The partitions depend on the random seed used in the splitting function.\n",
    "\n",
    "More robust strategies involve splitting the data in **multiple (complementary) subsets**.\n",
    "\n",
    "One of such strategies is the **k-fold cross-validation**, introduced during the lecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jnBd81Sk35QM"
   },
   "source": [
    "![k-fold cv](https://www.researchgate.net/profile/B_Aksasse/publication/326866871/figure/fig2/AS:669601385947145@1536656819574/K-fold-cross-validation-In-addition-we-outline-an-overview-of-the-different-metrics-used_W640.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rmolsnknM8cS"
   },
   "source": [
    "Example of a 5-fold cross-validation (CV) with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "551-qJzL8WKh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rMmmyxp5NX4P"
   },
   "source": [
    "A \"stratified\" 5-fold CV means that the folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "_Recap:_ the same random_state will generate the same splits. This is useful for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_VtvZEINnE6"
   },
   "source": [
    "To actually get the splitting indices and create the folds, we need to iterate over the `skf` object. Note that here I am using a Random Forest: feel free to experiment with other classifiers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-uoahY6yNcIv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Fold  1\n",
      "\n",
      "Accuracy on TEST set:  0.9285714285714286\n",
      "MCC on TEST set:  0.8406827880512091\n",
      "\n",
      "### Fold  2\n",
      "\n",
      "Accuracy on TEST set:  0.8888888888888888\n",
      "MCC on TEST set:  0.7470178808339961\n",
      "\n",
      "### Fold  3\n",
      "\n",
      "Accuracy on TEST set:  0.9814814814814815\n",
      "MCC on TEST set:  0.9597148699373932\n",
      "\n",
      "### Fold  4\n",
      "\n",
      "Accuracy on TEST set:  0.9814814814814815\n",
      "MCC on TEST set:  0.9586025865388215\n",
      "\n",
      "### Fold  5\n",
      "\n",
      "Accuracy on TEST set:  0.9629629629629629\n",
      "MCC on TEST set:  0.9219544457292888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get the number of splitting operations\n",
    "N = skf.get_n_splits(X, y)\n",
    "\n",
    "## reinitialize a classifier\n",
    "clf = RFC(n_estimators=500)\n",
    "\n",
    "## create empty lists to store the CV metrics\n",
    "acc_list = []\n",
    "mcc_list = []\n",
    "\n",
    "## split data and iterate over the splits,\n",
    "## computing classifier accuracy & MCC on each test partition\n",
    "n_fold = 1\n",
    "for (idx_tr, idx_ts) in skf.split(X, y):\n",
    "    print(\"### Fold \", n_fold)\n",
    "    X_train, Y_train = X[idx_tr], y[idx_tr]\n",
    "    X_test, Y_test = X[idx_ts], y[idx_ts]\n",
    "    print()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    acc = metrics.accuracy_score(Y_test, Y_test_pred)\n",
    "    mcc = metrics.matthews_corrcoef(Y_test, Y_test_pred)\n",
    "    print(\"Accuracy on TEST set: \", acc)\n",
    "    print(\"MCC on TEST set: \", mcc)\n",
    "    print()\n",
    "    ## append values to lists\n",
    "    acc_list.append(acc)\n",
    "    mcc_list.append(mcc)\n",
    "    \n",
    "    n_fold = n_fold + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q: how are the computed metrics on the different folds?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an estimate of the predictive performance of our model, we can average over the cross-validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation accuracy: 0.9486772486772488\n",
      "Average cross-validation MCC: 0.8855945142181417\n"
     ]
    }
   ],
   "source": [
    "## note: we need to convert the lists to numpy arrays before computing the means\n",
    "acc_avg = np.mean(np.array(acc_list))\n",
    "mcc_avg = np.mean(np.array(mcc_list))\n",
    "\n",
    "print(\"Average cross-validation accuracy:\", acc_avg)\n",
    "print(\"Average cross-validation MCC:\", mcc_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to be cool and have an even better estimate of how the model can generalize on new data, you can repeat the cross-validation several times (\"iterated cross-validation\"). Each time you need using a different random_state for generating the splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tI_6v1jNLKLF"
   },
   "source": [
    "# 6. Feature ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One type of insight you can gain from a machine learning model is the feature importance (or weight). Which genes are most likely to influence the classification of our neuroblastoma patients? Are some features pivotal, and others largely ignored?\n",
    "\n",
    "Because a Random Forest model branches repeatedly on different features, the model becomes \"aware\" of which features are particularly influential in classifiying a patient. \n",
    "\n",
    "Scikit-learn allows us to read this information off of a trained Random Forest model through the `feature_importances_` attribute (mind the trailing underscore!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lZAaTXJLKLH",
    "outputId": "2155231c-e50c-4c06-82c4-6b6a5f7c4ee2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain a random forest\n",
    "rf = RFC(n_estimators=500)\n",
    "rf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gH9yIYOLKLJ"
   },
   "source": [
    "For the sake of completeness make the predictions and check the classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rspvHmO0LKLK",
    "outputId": "7b131d8f-ebc8-4d03-9f38-ad90de735367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC =  0.8878456665075479\n",
      "ACC =  0.9454545454545454\n",
      "SENS =  0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "y_pred_rfc = rf.predict(x_ts)\n",
    "print('MCC = ', metrics.matthews_corrcoef(y_ts, y_pred_rfc))\n",
    "print('ACC = ', metrics.accuracy_score(y_ts, y_pred_rfc))\n",
    "print('SENS = ', metrics.recall_score(y_ts, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3k78HePLKLT"
   },
   "source": [
    "Now extract the feature importances and display the first 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7g9k5EHsLKLU",
    "outputId": "aa26094b-0e4a-48f0-be91-ecd2874ab204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking (top 10 features):\n",
      "ERCC6L.Gene_AceView  -  0.007557863909910913\n",
      "PHLDB1.Gene_AceView  -  0.005723642653223221\n",
      "LOC100287397.Gene_RefSeq  -  0.005440324197480472\n",
      "shular.Gene_AceView  -  0.005345517958746537\n",
      "C4orf43.Gene_AceView  -  0.005103896899982819\n",
      "C21orf45.Gene_AceView  -  0.004978595530022097\n",
      "ABCG4.Gene_AceView  -  0.004959479003626092\n",
      "lysly.Gene_AceView  -  0.004672365671712816\n",
      "MAD2L1.Gene_AceView  -  0.004649417519188538\n",
      "WDHD1.Gene_AceView  -  0.004625416159836063\n"
     ]
    }
   ],
   "source": [
    "# get the importances\n",
    "importances = rf.feature_importances_\n",
    "# sort by decreasing importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# get the gene names\n",
    "genes = data.columns.values\n",
    "# print the feature ranking\n",
    "print(\"Feature ranking (top 10 features):\")\n",
    "for f in range(10):\n",
    "    print(genes[indices[f]], \" - \", importances[indices[f]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **stem plot** is a common way to visually represent this kind of information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_feat = 10\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.stem(range(n_feat), importances[indices[:n_feat]])\n",
    "plt.xticks(range(n_feat), genes[indices[:n_feat]], rotation=\"vertical\")\n",
    "plt.xlim([-1, n_feat])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Optional topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6khMtHGSLKK3"
   },
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlHdQ4xSLKK4"
   },
   "source": [
    "As mentioned in the lecture, Scikit learn offers a very useful and flexible tool for parameter tuning called _GridSearchCV_. While the tool is very sophisticated and efficient, it is useful to at least try an example _by hand_ to understand what is happening in the background.\n",
    "\n",
    "For this example we use a linear SVM and try to tune the C parameter. You might remember from the lectures that the paramenter C essentially controls how much we want to avoid misclassifying each training example. Large values of C result in smaller margins, i.e. closer fitting to the training data. As mentioned in the classes, the drawback is over-fitting, resulting in poor generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all, let's get a clean train/test split of the original data\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=78)\n",
    "# rescale\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_tr)\n",
    "x_tr = scaler.transform(x_tr)\n",
    "x_ts = scaler.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XG01P5fdLKK6",
    "outputId": "099e6404-c7fd-414a-b49a-4092af095c57",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## define the sequence of C values we want to use in the search of the best one\n",
    "C_list = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "for C in C_list:\n",
    "    print('C = ', C)\n",
    "    svc = SVC(kernel = 'linear', C=C)\n",
    "    svc.fit(x_tr, y_tr)\n",
    "    class_pred_ts = svc.predict(x_ts)\n",
    "    print('MCC = ', metrics.matthews_corrcoef(y_ts, class_pred_ts))\n",
    "    print('ACC = ', metrics.accuracy_score(y_ts, class_pred_ts))\n",
    "    print('SENS = ', metrics.recall_score(y_ts, class_pred_ts), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hhn8hFrJLKK-"
   },
   "source": [
    "Depending on the splits I generated with train_test_split, I get the highest MCC for C=1e-5, which I consider the optimal parameter in this setting. You may get different values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oh8VvvpcLKK_"
   },
   "source": [
    "**Optional exercise:** as you already saw in the lectures, there are many parameters that can be tuned, also when considering only one simple classifier. For example, if you consider SVM with 'rbf' kernel, you could check performance changes with different values of C **and** gamma, for example using two nested loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPtC-EBSLKK_"
   },
   "outputs": [],
   "source": [
    "## space for exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJC3MFEALKLB"
   },
   "source": [
    "As we mentioned, Scikit offers fully automated parameter tuning engine. We illustrate its power with a simple example on our data. We use GridSearchCV to search through a grid of C and gamma parameter options for SVM with 'rbf' kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utM1ALBfLKLC",
    "outputId": "d96dc041-2f6f-4f1a-bca5-70310d1f79ee"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "\n",
    "C_range = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gamma_range = ['auto', 0.01, 1]\n",
    "# the parameter grid is defined as a dictionary {<parameter>: <values>} for each parameter\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# define the type of cross-validation for the grid search\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.5, random_state=42)\n",
    "# create a GridSearchCV object\n",
    "grid = GridSearchCV(SVC(kernel=\"rbf\"), param_grid=param_grid, cv=cv, n_jobs=4)\n",
    "# go!\n",
    "grid.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters and the corresponding average cross-validated score are available in the `best_params_` and `best_score_` attributes, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: GridSearchCV by default does not maximize the MCC, but the accuracy._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model with the best parameters and predict on the test set, computing a few metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"rbf\", C=grid.best_params_['C'], gamma=grid.best_params_['gamma'])\n",
    "clf.fit(x_tr, y_tr)\n",
    "y_pred = clf.predict(x_ts)\n",
    "print('MCC = ', metrics.matthews_corrcoef(y_ts, y_pred))\n",
    "print('ACC = ', metrics.accuracy_score(y_ts, y_pred))\n",
    "print('SENS = ', metrics.recall_score(y_ts, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "practical_neuroblastoma_partII_v0.3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
